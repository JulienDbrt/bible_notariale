# Backend Environment Configuration

# Database Configuration - Supabase Cloud
SUPABASE_URL=https://your-project.supabase.co
SUPABASE_KEY=<YOUR_SUPABASE_SERVICE_ROLE_KEY>

# File Upload Configuration
UPLOAD_DIR=/app/uploads
MAX_FILE_SIZE=50MB
# Supported file extensions (Docling supports 15+ formats with OCR + custom EML parser)
ALLOWED_EXTENSIONS=pdf,docx,txt,md,pptx,xlsx,odt,html,png,jpg,jpeg,tiff,wav,mp3,asciidoc,eml

# OpenRouter Configuration (pour LLM Extraction uniquement avec gpt-oss-120b)
OR_API_KEY=<YOUR_OPENROUTER_API_KEY>
OR_PROVIDER="custom"
OR_MODEL="openai/gpt-oss-120b"
OR_ENDPOINT="https://openrouter.ai/api/v1"

EMBEDDING_PROVIDER="openai"
# Options disponibles:
#   - text-embedding-3-small  : 1536 dimensions (natif), plus rapide, moins coûteux
#   - text-embedding-3-large  : 3072 dimensions (natif), meilleure qualité
#   - text-embedding-ada-002  : 1536 dimensions (ancien modèle)
EMBEDDING_MODEL="text-embedding-3-small"
EMBEDDING_ENDPOINT="https://api.openai.com/v1"
EMBEDDING_API_KEY=<YOUR_OPENAI_API_KEY>
# Dimensions natives: 1536 pour small/ada-002, 3072 pour large
# Vous pouvez réduire les dimensions via l'API pour économiser l'espace
EMBEDDING_DIMENSIONS=1536

OPENAI_API_KEY=<YOUR_OPENAI_API_KEY>

#EMBEDDING_PROVIDER="fastembed"
#EMBEDDING_MODEL="sentence-transformers/all-MiniLM-L6-v2"
#EMBEDDING_DIMENSIONS = 384
# Token Configuration for Document Processing
ANALYSIS_CHUNK_SIZE_TOKENS=60000  # Taille max pour l'extraction d'entités (LLM)
RETRIEVAL_CHUNK_SIZE_TOKENS=1024  # Taille des chunks pour la recherche vectorielle (UPGRADED)
RETRIEVAL_OVERLAP_TOKENS=200      # Chevauchement entre chunks vectoriels (UPGRADED)
EMBEDDING_TOKEN_LIMIT_PER_CHUNK=8190  # Limite max par chunk pour l'API embedding
EMBEDDING_BATCH_TOKEN_LIMIT=250000    # Limite max par batch d'embeddings
LLM_EXTRACTION_MAX_TOKENS=10096    # Tokens max pour la réponse du LLM d'extraction

# LLM Model Configuration avec endpoints granulaires
# LLM_EXTRACTION : Extraction d'entités et relations depuis les documents
LLM_EXTRACTION_MODEL=gpt-4.1-mini-2025-04-14
#LLM_EXTRACTION_MODEL=openai/gpt-oss-120b     # Alternative: modèle GPT-OSS 120B (OpenRouter uniquement)
LLM_EXTRACTION_ENDPOINT="openai"               # Options: "openai" ou "openrouter"
LLM_EXTRACTION_TEMPERATURE=0.3                 # Température pour extraction d'entités

# LLM_PLANNER : Planification et sélection de stratégie RAG
LLM_PLANNER_MODEL=gpt-4.1-nano-2025-04-14     # Modèle léger et rapide pour planification
LLM_PLANNER_ENDPOINT="openai"                  # Options: "openai" ou "openrouter"
LLM_PLANNER_TEMPERATURE=0.3                    # Température pour planification

# LLM_SYNTHESIS : Synthèse de réponses finales avec contexte
LLM_SYNTHESIS_MODEL=gpt-4.1-2025-04-14        # Modèle premium pour réponses de qualité
LLM_SYNTHESIS_ENDPOINT="openai"                # Options: "openai" ou "openrouter"
LLM_SYNTHESIS_TEMPERATURE=0.6                  # Température pour synthèse (plus créatif)

# Neo4j Graph Database Configuration (Remote Instance)
NEO4J_URL=bolt://neo4j.chatbotpro.fr:7687
NEO4J_USERNAME=neo4j
NEO4J_PASSWORD=your_password
NEO4J_BROWSER_URL=https://neo4j.chatbotpro.fr:7474

# Minio Configuration
MINIO_ENDPOINT=minio.chatbotpro.fr
MINIO_ROOT_USER=minioadmin
MINIO_ROOT_PASSWORD=rqven19lswtvb1tq
MINIO_BROWSER_REDIRECT_URL=http://admin-minio.chatbotpro.fr
MINIO_BROWSER_REDIRECT=false
MINIO_SECURE=true

# Application Configuration
ENVIRONMENT=development
DEBUG=false
