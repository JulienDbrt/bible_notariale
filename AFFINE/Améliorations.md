# Am√©liorations

# PLAN D'AM√âLIORATION CHATBOT - Synth√®se Compl√®te

## Chambre des Notaires de Caen - Phase 1 bis

**Version** : 1.0
**Date** : 18 novembre 2025
**Contexte** : 10/15 tests √©chou√©s, pattern clair = mauvaise s√©lection de sources

***

## üìà SYNTH√àSE STRAT√âGIQUE PAR IMPACT/EFFORT

| #      | Optimisation                      | Impact | Effort | Priorit√©      | Type              |
| ------ | --------------------------------- | ------ | ------ | ------------- | ----------------- |
| **1**  | Collections th√©matiques + Routing | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  | 2j     | üî• CRITIQUE   | S√©lection sources |
| **2**  | Top-k + Reranking LLM             | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  | 1j     | üî• CRITIQUE   | Recherche         |
| **3**  | Enrichissement m√©tadonn√©es Bible  | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê  | 0.5j   | üî• CRITIQUE   | Fondation         |
| **4**  | Prompt expertise notariale        | ‚≠ê‚≠ê‚≠ê‚≠ê   | 0.5j   | üî• HAUTE      | Qualit√© r√©ponse   |
| **5**  | D√©tection hors p√©rim√®tre          | ‚≠ê‚≠ê‚≠ê‚≠ê   | 1j     | üî• HAUTE      | Fiabilit√©         |
| **6**  | Expansion requ√™te (lexique)       | ‚≠ê‚≠ê‚≠ê‚≠ê   | 0.5j   | ‚ö° RAPIDE      | Recherche         |
| **7**  | Boost questions typiques          | ‚≠ê‚≠ê‚≠ê‚≠ê   | 1j     | ‚ö° RAPIDE      | Bible             |
| **8**  | Caching embeddings                | ‚≠ê‚≠ê‚≠ê    | 0.5j   | ‚ö° RAPIDE      | Performance       |
| **9**  | Parall√©lisation recherche         | ‚≠ê‚≠ê‚≠ê    | 0.5j   | ‚ö° RAPIDE      | Performance       |
| **10** | Boost vocabulaire sp√©cifique      | ‚≠ê‚≠ê‚≠ê    | 0.5j   | üü¢ MOYEN      | Bible             |
| **11** | Graph traversal relations         | ‚≠ê‚≠ê‚≠ê‚≠ê   | 1.5j   | üü¢ MOYEN      | Multi-docs        |
| **12** | Graph traversal entit√©s           | ‚≠ê‚≠ê‚≠ê    | 2j     | üü° LONG TERME | Pr√©cision         |
| **13** | Chunking avec overlap             | ‚≠ê‚≠ê‚≠ê    | 1.5j   | üü° LONG TERME | Re-indexation     |

**TOTAL CRITIQUE + HAUTE** : 5.5 jours ‚Üí Objectif 80% atteint
**TOTAL avec RAPIDE** : 8 jours ‚Üí Syst√®me optimis√©
**TOTAL complet** : 12 jours ‚Üí Excellence

***

## üéØ ANALYSE DES PROBL√àMES ACTUELS

### **Probl√®me #1 : Mauvaise s√©lection de sources (70% des √©checs)**

**Tests √©chou√©s** :

* TEST\_DEON\_001 : Guide n√©go immo au lieu du RPN
* TEST\_IMMO\_001/002 : Mauvaises sources
* TEST\_RH\_001 : Mauvaises sources
* TEST\_ASSUR\_001 : Mauvaises sources

**Cause** : 234 documents interrog√©s uniform√©ment, pas de filtrage intelligent

**Solutions** : #1, #3, #6

***

### **Probl√®me #2 : R√©ponses incompl√®tes (20% des √©checs)**

**Tests √©chou√©s** :

* TEST\_USER\_001 : Info partielle
* TEST\_USER\_007 : Contexte manquant

**Cause** : top\_k = 5 trop faible, pas de reranking

**Solutions** : #2, #7, #11

***

### **Probl√®me #3 : Qualit√© juridique insuffisante (10% des √©checs)**

**Tests √©chou√©s** :

* TEST\_DEON\_001 : Ne mentionne pas le conflit d'int√©r√™ts

**Cause** : Prompts g√©n√©riques, pas calibr√©s m√©tier notarial

**Solutions** : #4, #5

***

## üî• PRIORIT√â CRITIQUE (5.5 jours) - Objectif 80%

### **#1. Collections th√©matiques + Document Routing**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (-70% erreurs de sources)
**Effort** : 2 jours

**Probl√®me** : Les 234 documents sont trait√©s uniform√©ment. Question sur d√©ontologie ‚Üí cherche aussi dans guides immobiliers.

**Solution en 2 √©tapes** :

#### **√âtape 1A : Enrichir Neo4j avec cat√©gories m√©tier**



python

```
# scripts/enrich_neo4j_categories.py# Charger m√©tadonn√©es valid√©esmetadata_dir = Path("_metadata/documents")for meta_file in metadata_dir.glob("*.metadata.json"): metadata = json.load(open(meta_file)) query ="""  MATCH (doc:Document {documentId: $doc_id})  SET doc.categories_metier = $categories,  doc.type_document = $type,  doc.priorite = $priorite  """await neo4j.run(query,{"doc_id": metadata["document_id"],"categories": metadata.get("categories_metier",[]),"type": metadata["classification"]["type_document"],"priorite": metadata.get("priorite",5)})
```

#### **√âtape 1B : Routing avant recherche**



python

```
# backend/app/services/notaria_rag_service.pyasyncdef_reasoning_step(self, question:str):"""AJOUT : Routing intelligent."""# 1. Classifier la question par cat√©gorie categories =await self._classify_question(question)# 2. Filtrer documents par cat√©gorie + priorit√© relevant_doc_ids =await self._filter_docs_by_category(categories)# 3. Recherche vectorielle UNIQUEMENT dans docs pertinents chunks =await self.neo4j.hybrid_search( query=question, document_filter=relevant_doc_ids,# NOUVEAU top_k=20)return chunks asyncdef_classify_question(self, question:str)-> List[str]:"""LLM l√©ger pour identifier 1-2 cat√©gories pertinentes.""" prompt =f"""  Classifie cette question notariale :  Cat√©gories possibles :  - DEONTOLOGIE : secret professionnel, conflits, RPN, sanctions  - IMMOBILIER : n√©gociation, mandats, transactions, vente  - RH : salaires, CCN, cong√©s, licenciement, formation  - ASSURANCES : cyber, RCP, garanties, franchises  - PROCEDURE : m√©diation, r√©clamations, tribunal, discipline  - FISCAL : imp√¥ts, TPF, droits mutation  - SUCCESSION : h√©ritage, testament, partage  Question: {question} Retourne JSON: ["CATEGORIE1", "CATEGORIE2"]  Maximum 2 cat√©gories, ordonn√©es par pertinence.  """ response =await self.extraction_client.chat.completions.create( model="gpt-4o-mini", messages=[{"role":"user","content": prompt}], temperature=0)return json.loads(response.choices[0].message.content)asyncdef_filter_docs_by_category(self, categories: List[str])-> List[str]:"""R√©cup√®re les documents dans ces cat√©gories, tri√©s par priorit√©.""" query ="""  MATCH (doc:Document)  WHERE ANY(cat IN doc.categories_metier WHERE cat IN $categories)  RETURN doc.documentId as doc_id  ORDER BY doc.priorite DESC  LIMIT 50  """ result =await self.neo4j.run(query,{"categories": categories})return[record["doc_id"]for record in result]
```

**R√©sultat attendu** :

* Question d√©ontologie ‚Üí cherche dans 45 docs au lieu de 234
* Documents priorit√© 10 (RPN, Code) en premier
* -70% d'erreurs de s√©lection de sources

***

### **#2. Top-k augment√© + Reranking LLM**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (+50% compl√©tude)
**Effort** : 1 jour

**Probl√®me** : top\_k = 5 trop faible ‚Üí contexte insuffisant. Pas de reranking ‚Üí chunks m√©diocres passent.

**Solution** :



python

```
# backend/app/services/notaria_rag_service.pyasyncdef_acting_step(self, question:str, chunks: List):"""MODIFICATION : Plus de chunks + reranking."""# 1. Phase initiale : r√©cup√©rer LARGEMENT (20 chunks) initial_chunks = chunks[:20]# Au lieu de 5# 2. NOUVEAU : Reranking avec LLM best_chunks =await self._rerank_with_llm(question, initial_chunks, target=8)# 3. Synth√®se (code existant) answer =await self._synthesize_answer(question, best_chunks)return answer asyncdef_rerank_with_llm( self, question:str, chunks: List, target:int=8)-> List:"""Reranke avec gpt-4o-mini pour scorer chaque chunk."""# Formater les chunks chunks_formatted ="\n\n".join([f"[Passage {i+1}]\n{chunk.text[:300]}..."for i, chunk inenumerate(chunks)]) prompt =f"""  Question: {question} Score chaque passage de 0 √† 10 selon sa pertinence pour r√©pondre.  Crit√®res:  - 10 : R√©pond directement √† la question  - 7-9 : Contient des √©l√©ments de r√©ponse importants  - 4-6 : Contexte utile mais pas essentiel  - 0-3 : Peu ou pas pertinent  Passages: {chunks_formatted} Retourne UNIQUEMENT un JSON:  [{{"passage_id": 1, "score": 8}}, {{"passage_id": 2, "score": 5}}, ...]  """ response =await self.extraction_client.chat.completions.create( model="gpt-4o-mini", messages=[{"role":"user","content": prompt}], temperature=0) scores = json.loads(response.choices[0].message.content)# Trier par score et garder top N scores.sort(key=lambda x: x["score"], reverse=True) best_ids =[s["passage_id"]-1for s in scores[:target]]return[chunks[i]for i in best_ids]
```

**R√©sultat attendu** :

* Contexte plus riche (20 chunks au lieu de 5)
* S√©lection intelligente des 8 meilleurs
* +50% de compl√©tude des r√©ponses

***

### **#3. Enrichissement m√©tadonn√©es Bible Notariale**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê (D√©bloque #6, #7, #10)
**Effort** : 0.5 jour

**Probl√®me** : Les m√©tadonn√©es de la Bible (lexique, questions typiques, vocabulaire sp√©cifique) sont dans des JSON, pas dans Neo4j.

**Solution** :



python

```
# scripts/enrich_neo4j_from_bible.pyasyncdefenrich_neo4j_complete():"""Injecte TOUTES les m√©tadonn√©es Bible dans Neo4j.""" metadata_dir = Path("_metadata/documents")for meta_file in metadata_dir.glob("*.metadata.json"): metadata = json.load(open(meta_file)) query ="""  MATCH (doc:Document {documentId: $doc_id})  SET  doc.categories_metier = $categories,  doc.type_document = $type,  doc.priorite = $priorite,  doc.mots_cles = $mots_cles,  doc.annee_reference = $annee,  doc.domaines_juridiques = $domaines,  doc.questions_typiques = $questions,  doc.vocabulaire_specifique = $vocab_spec,  doc.relations_documentaires = $relations  RETURN doc  """await neo4j.run(query,{"doc_id": metadata["document_id"],"categories": metadata.get("categories_metier",[]),"type": metadata["classification"]["type_document"],"priorite": metadata.get("priorite",5),"mots_cles": metadata["mots_cles"],"annee": metadata["classification"]["annee_reference"],"domaines": metadata["classification"]["domaines_juridiques"],"questions": metadata.get("questions_typiques",[]),"vocab_spec": json.dumps(metadata.get("vocabulaire_specifique",[])),"relations": json.dumps(metadata.get("relations_documentaires",{}))})print(f"‚úÖ {len(list(metadata_dir.glob('*.metadata.json')))} documents enrichis")
```

**R√©sultat attendu** :

* 234 documents avec m√©tadonn√©es compl√®tes dans Neo4j
* D√©bloque toutes les optimisations Bible (#6, #7, #10)
* Base solide pour √©volutions futures

***

### **#4. Prompt syst√®me avec expertise notariale**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê (+35% qualit√© juridique)
**Effort** : 0.5 jour

**Probl√®me** : Prompt g√©n√©rique, pas calibr√© sur le vocabulaire et les exigences du m√©tier notarial.

**Solution** :



python

```
# backend/app/services/notaria_rag_service.pySYSTEM_PROMPT_NOTARIAL =""" Tu es un assistant juridique expert en droit notarial fran√ßais, sp√©cialis√© dans le conseil aux notaires. M√âTHODOLOGIE DE R√âPONSE (OBLIGATOIRE) : 1. ANALYSE : Identifier la th√©matique juridique (d√©ontologie, immobilier, RH, etc.) 2. PRINCIPES : √ânoncer les principes juridiques applicables [avec Passage X] 3. R√àGLES : D√©tailler les r√®gles sp√©cifiques [avec Passage X] 4. EXCEPTIONS : Mentionner les exceptions ou cas particuliers si applicable 5. CONS√âQUENCES : √âvoquer les risques/sanctions si pertinent 6. CONSEIL : Conclure par un conseil pratique orient√© action R√àGLES STRICTES : - TOUJOURS v√©rifier s'il existe un conflit d'int√©r√™ts potentiel dans les questions d√©ontologiques - TOUJOURS citer les sanctions disciplinaires si la question concerne une obligation - JAMAIS inventer d'information (hallucination = faute grave) - Si information partielle : "Les documents mentionnent [X] mais ne pr√©cisent pas [Y]." - Si hors p√©rim√®tre : "Cette question rel√®ve de [domaine]. Je recommande de consulter [expert]." VOCABULAIRE NOTARIAL REQUIS : - "RPN" (R√®glement Professionnel National), pas "r√®glement" - "Office notarial", pas "√©tude" ou "cabinet" - "Instrumenter" pour recevoir un acte authentique - "Minute" pour l'original de l'acte - "Exp√©dition" pour la copie d√©livr√©e - "√âmoluments" pour la tarification r√©glement√©e - "Honoraires" pour la r√©mun√©ration libre STRUCTURE DE CITATION : - Format : [Passage X] apr√®s chaque affirmation bas√©e sur un document - Minimum 1 citation par paragraphe - Citations pr√©cises, jamais vagues """asyncdef_synthesize_answer(self, question:str, chunks: List)->str:"""G√©n√©ration avec prompt expert.""" context_str ="\n\n".join([f"[Passage {i+1}]\nDocument: {chunk.document_title}\n{chunk.text}"for i, chunk inenumerate(chunks)]) prompt =f"""{SYSTEM_PROMPT_NOTARIAL}PASSAGES EXTRAITS : {context_str}QUESTION : {question}R√âPONSE STRUCTUR√âE (suivre la m√©thodologie ci-dessus) :"""# Code g√©n√©ration existant...
```

**R√©sultat attendu** :

* Vocabulaire notarial correct
* Structure juridique des r√©ponses
* Mention syst√©matique des risques/sanctions
* +35% de qualit√© per√ßue par les notaires

***

### **#5. D√©tection hors p√©rim√®tre**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê (100% faux positifs √©limin√©s)
**Effort** : 1 jour

**Probl√®me** :

* TEST\_HORSPER\_001 : "Puis-je monter une SCI" ‚Üí r√©pond au lieu de refuser
* TEST\_HORSPER\_002 : "Capitale de France" ‚Üí cherche dans docs au lieu de r√©pondre directement

**Solution** :



python

```
# backend/app/services/notaria_rag_service.pyasyncdefquery(self, question:str)->str:"""Point d'entr√©e avec d√©tection hors p√©rim√®tre."""# NOUVEAU : Classifier le scope AVANT tout traitement scope =await self._classify_question_scope(question)if scope =="CONNAISSANCE_GENERALE":returnawait self._answer_general_knowledge(question)elif scope =="CONSEIL_PERSONNALISE":return self._refuse_conseil_personnalise()elif scope =="HORS_PERIMETRE":return self._refuse_hors_perimetre(question)else:# PERIMETRE_NOTARIALreturnawait self._full_rag_pipeline(question)asyncdef_classify_question_scope(self, question:str)->str:"""Classifie en 4 scopes.""" prompt =f"""  Classifie cette question en UNE cat√©gorie :  1. PERIMETRE_NOTARIAL  ‚Üí Question sur d√©ontologie, CCN, proc√©dure notariale, r√©glementation profession  ‚Üí Exemples : "Qu'est-ce que le RPN ?", "Obligations LCB-FT ?", "Avenant 59 CCN ?"  2. CONNAISSANCE_GENERALE  ‚Üí Question de culture g√©n√©rale, d√©finition courante, fait √©tabli  ‚Üí Exemples : "Capitale de France ?", "Qu'est-ce qu'une SAS ?", "D√©finition contrat ?"  3. CONSEIL_PERSONNALISE  ‚Üí Question demandant un avis sur un cas sp√©cifique client  ‚Üí Exemples : "Puis-je accepter ce mandat ?", "Dois-je refuser ce dossier ?"  4. HORS_PERIMETRE  ‚Üí Question sans rapport avec le notariat  ‚Üí Exemples : "Recette tarte aux pommes ?", "M√©t√©o demain ?"  Question: {question} R√©ponds UNIQUEMENT le nom de la cat√©gorie.  """ response =await self.extraction_client.chat.completions.create( model="gpt-4o-mini", messages=[{"role":"user","content": prompt}], temperature=0)return response.choices[0].message.content.strip()asyncdef_answer_general_knowledge(self, question:str)->str:"""R√©pond directement sans chercher dans les documents.""" response =await self.synthesis_client.chat.completions.create( model="gpt-4o", messages=[{"role":"system","content":"Tu es un assistant. R√©ponds bri√®vement et factuellement."},{"role":"user","content": question}], temperature=0)return response.choices[0].message.content def_refuse_conseil_personnalise(self)->str:return"""  Je fournis des informations r√©glementaires et documentaires sur le notariat,  mais je ne peux pas donner de conseil personnalis√© sur des cas clients sp√©cifiques.  Pour une situation particuli√®re, je vous recommande de :  - Consulter votre Chambre interd√©partementale  - Contacter le service juridique du CSN  - √âchanger avec un confr√®re sp√©cialis√©  """def_refuse_hors_perimetre(self, question:str)->str:return"""  Cette question ne rel√®ve pas du p√©rim√®tre de mes connaissances documentaires  sur le notariat fran√ßais (d√©ontologie, CCN, proc√©dures professionnelles).  Je peux vous aider sur des questions concernant :  - La d√©ontologie notariale (RPN, secret professionnel, conflits)  - La Convention Collective Nationale  - Les proc√©dures professionnelles  - Les obligations r√©glementaires (LCB-FT, m√©diation, etc.)  """
```

**R√©sultat attendu** :

* 0 faux positifs hors p√©rim√®tre
* R√©ponses directes sur connaissances g√©n√©rales
* Refus polis et orient√©s sur conseils personnalis√©s

***

## ‚ö° OPTIMISATIONS RAPIDES (2.5 jours) - Gains marginaux importants

### **#6. Expansion de requ√™te avec lexique notarial**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê (+30% recall)
**Effort** : 0.5 jour

**Solution** :



python

```
# backend/app/services/query_expander.pyclassQueryExpander:def__init__(self):withopen('_metadata/vocabulaire_notarial.json')as f: self.lexique = json.load(f)defexpand(self, query:str)->str:"""  LCB-FT ‚Üí "LCB-FT Lutte Contre Blanchiment Financement Terrorisme LAB"  CCN ‚Üí "CCN Convention Collective Nationale IDCC 2205"  """ expanded =[query]for acronyme, expansion in self.lexique.items():if acronyme.lower()in query.lower():ifisinstance(expansion,str): expanded.append(expansion)elifisinstance(expansion,list): expanded.extend(expansion)return" ".join(expanded)# Int√©grationasyncdef_reasoning_step(self, question:str): expanded_query = self.query_expander.expand(question) chunks =await self.neo4j.hybrid_search(query=expanded_query,...)
```

***

### **#7. Boost s√©mantique questions typiques**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê (+25% pr√©cision ranking)
**Effort** : 1 jour

**Solution** :



python

```
# backend/app/services/question_matcher.pyasyncdefcompute_boost(user_q:str, doc_meta:dict)->float:"""Compare avec questions typiques du document."""ifnot doc_meta.get('questions_typiques'):return1.0 user_emb =await get_embedding(user_q) max_sim =0.0for typical_q in doc_meta['questions_typiques']: typical_emb =await get_embedding(typical_q) sim = cosine_similarity(user_emb, typical_emb) max_sim =max(max_sim, sim)return1.0+ max_sim # Boost 1.0 √† 2.0# Int√©grer dans rerankingasyncdef_rerank_with_llm(self, question, chunks, target=8): llm_scores =await self._llm_rerank(question, chunks) final_scores =[]for chunk, score inzip(chunks, llm_scores): doc_meta =await self._get_doc_metadata(chunk.document_id) boost =await self.question_matcher.compute_boost(question, doc_meta) final_scores.append((chunk, score * boost)) final_scores.sort(key=lambda x: x[1], reverse=True)return[chunk for chunk, _ in final_scores[:target]]
```

***

### **#8. Caching embeddings**

**Impact** : ‚≠ê‚≠ê‚≠ê (-40% temps sur requ√™tes similaires)
**Effort** : 0.5 jour

**Solution** :



python

```
import redis from hashlib import sha256 redis_client = redis.Redis(host='localhost', port=6379, db=0)asyncdefget_or_create_embedding(text:str): cache_key =f"emb:{sha256(text.encode()).hexdigest()}" cached = redis_client.get(cache_key)if cached:return json.loads(cached) embedding =await openai_client.embeddings.create(...) redis_client.setex(cache_key,86400, json.dumps(embedding))return embedding
```

***

### **#9. Parall√©lisation recherche**

**Impact** : ‚≠ê‚≠ê‚≠ê (-25% temps)
**Effort** : 0.5 jour

**Solution** :



python

```
import asyncio # Au lieu de s√©quentielvector_results, fulltext_results =await asyncio.gather( self.vector_search(...), self.fulltext_search(...))
```

***

## üü¢ OPTIMISATIONS MOYENNES (3 jours) - Si <80% apr√®s priorit√©s

### **#10. Boost vocabulaire sp√©cifique**

**Impact** : ‚≠ê‚≠ê‚≠ê (+15% pertinence)
**Effort** : 0.5 jour

**Solution** :



python

```
asyncdefapply_term_boosting(chunks, metadata_by_doc):for chunk in chunks: doc_meta = metadata_by_doc[chunk.document_id] vocab_spec = doc_meta.get('vocabulaire_specifique',[]) boost =1.0for term_info in vocab_spec:if term_info['terme'].lower()in chunk.text.lower(): boost *=1.5for syn in term_info.get('synonymes',[]):if syn.lower()in chunk.text.lower(): boost *=1.3 chunk.score *= boost returnsorted(chunks, key=lambda x: x.score, reverse=True)
```

***

### **#11. Graph traversal relations documentaires**

**Impact** : ‚≠ê‚≠ê‚≠ê‚≠ê (+40% sur multi-docs)
**Effort** : 1.5 jour

**Solution** :



python

```
asyncdeffind_related_docs(doc_ids: List[str])-> List[str]:"""  Avenant 59 "modifie" Article 29.5  ‚Üí Si on trouve Avenant 59, on r√©cup√®re aussi Article 29.5 original  """ related_ids =set(doc_ids)for doc_id in doc_ids: metadata =await get_doc_metadata(doc_id) relations = metadata.get('relations_documentaires',{})for rel_type, related_list in relations.items(): related_ids.update(related_list)returnlist(related_ids)# Int√©grer pour questions multi-documentsif is_multi_document_question(question): initial_doc_ids ={c.document_id for c in chunks[:5]} related_doc_ids =await find_related_docs(list(initial_doc_ids)) additional_chunks =await neo4j.hybrid_search( query=question, document_filter=related_doc_ids, top_k=10) chunks = chunks + additional_chunks
```

***

## üü° LONG TERME (3.5 jours) - Si vraiment n√©cessaire

### **#12. Graph traversal entit√©s**

**Impact** : ‚≠ê‚≠ê‚≠ê (+30% pr√©cision factuelles)
**Effort** : 2 jours

**Solution** :



python

```
# Si trouve "Contrat Cyber MMA", r√©cup√©rer automatiquement# toutes les franchises, dates, num√©ros li√©sMATCH (chunk)-[:HAS_ENTITY]->(entity:Organization {name:"MMA IARD"})MATCH (entity)<-[:HAS_ENTITY]-(related_chunk)WHERE related_chunk.text CONTAINS "√©ch√©ance" OR related_chunk.text CONTAINS "franchise"RETURN related_chunk
```

***

### **#13. Chunking avec overlap**

**Impact** : ‚≠ê‚≠ê‚≠ê (+20% coh√©rence)
**Effort** : 1.5 jour (re-indexation)

**Solution** :



python

```
CHUNK_SIZE =512CHUNK_OVERLAP =100# 20% overlapchunk_with_context =f""" [Document: {doc_title}] [Section: {section_name}] {chunk_text}[Fin de chunk - Document: {doc_title}] """
```



[Analyse Graph](file:///workspace/1069f0be-6b6a-4c78-b854-f8b5330ffa8b/hXKmkA7RXf2Ms_TUPYOzZ)

[Grammaire notariale](file:///workspace/1069f0be-6b6a-4c78-b854-f8b5330ffa8b/zcvDAIAB8v5f30rqoWJrK)

[UI de Recherche & Knowledge Base](file:///workspace/1069f0be-6b6a-4c78-b854-f8b5330ffa8b/jE5gFtIuYo2xiIbGyXIbk)

[notes](file:///workspace/1069f0be-6b6a-4c78-b854-f8b5330ffa8b/in0LqVIhFLQb7io7MKMYu)
